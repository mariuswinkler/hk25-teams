{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea896db9-6547-4be5-8862-cfd13443d297",
   "metadata": {},
   "source": [
    "# Track cyclones with TempestExtremes within JASMIN Jupyterhub\n",
    "TempestExtremes is a C++ software for detecting and manipulating features in climate data.  \n",
    "The Software is described two papers:\n",
    "* Ullrich, P.A., C.M. Zarzycki, E.E. McClenny, M.C. Pinheiro, A.M. Stansfield and K.A. Reed (2021) \"TempestExtremes v2.1: A community framework for feature detection, tracking and analysis in large datasets\" Geosci. Model. Dev. 14, pp. 5023â€“5048, doi: 10.5194/gmd-14-5023-2021.\n",
    "* Ullrich, P.A. and C.M. Zarzycki (2017) \"TempestExtremes v1.0: A framework for scale-insensitive pointwise feature tracking on unstructured grids\" Geosci. Model. Dev. 10, pp. 1069-1090, doi: 10.5194/gmd-10-1069-2017.\n",
    "\n",
    "And you can find the documentation here: Please find documentation here: https://climate.ucdavis.edu/tempestextremes.php"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078085fc-ae8c-4d56-a808-5dc164def4ca",
   "metadata": {},
   "source": [
    "### To do in terminal before the notebook\n",
    "A. If you don't already have a dedicated environment.\n",
    "1. Create a conda environment\n",
    "```\n",
    "conda create -n tempestextremes\n",
    "conda init\n",
    "bash\n",
    "conda activate tempestextremes\n",
    "```\n",
    "2. Install kernels to work with the notebooks\n",
    "```\n",
    "conda install ipykernels\n",
    "python -m ipykernel install --user --name=tempestextremes\n",
    "conda install bash_kernel\n",
    "```\n",
    "3. Restart jupyterhub\n",
    "4. (Still in terminal) Install TempestExtremes in the environment\n",
    "```\n",
    "conda init\n",
    "bash\n",
    "conda activate tempestextremes\n",
    "conda install -c conda-forge tempest-extremes\n",
    "```\n",
    "\n",
    "B. If you already created a hackathon-specific conda environment (following e.g. https://digital-earths-global-hackathon-uk.github.io/#software-stack)\n",
    "1. `conda activate hackathon`\n",
    "2. `python -m ipykernel install --user --name=name-of-environment` (If not already done)\n",
    "3. `conda install bash kernels`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3bb599-ff5c-4a80-a42b-c42f16c6e864",
   "metadata": {},
   "source": [
    "### This notebook\n",
    "NB: Open this notebook with bash kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bef9dc9-9f53-4e27-aae0-79562595fc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate the conda environment in which tempestextremes has been install\n",
    "conda activate tempestextremes\n",
    "# If you have a message saying you need to initalize conda: \n",
    "## create a new cell with the `conda init` command\n",
    "## Run that cell\n",
    "## Delete the cell\n",
    "## Restart your kernel\n",
    "## Run the notebook again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703b4342-c067-4367-9586-dd386ea286bc",
   "metadata": {},
   "source": [
    "To track cyclone with TempestExtremes, you need to first run `DetectNodes` to find suitable \"candidate nodes\" (points in space and time that could be cyclones), and second run `StitchNodes` to \"Stitch\" the candidate nodes into tracks. In this notebook, we show some minimal examples of how that works, and then provide the code for the UZ (Ullrich & Zarzycki, sometimes also known as the eponymous \"TempestExtremes\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c46a21-43a7-4893-96a8-35bbc2b00bf2",
   "metadata": {},
   "source": [
    "## Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4673fd-b8e3-4a4a-a463-b926e804d78d",
   "metadata": {},
   "source": [
    "### Minimal `DetectNodes` command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbb22cc-52dd-4847-83ea-607416d62041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we only find SLP minima in one file\n",
    "# The file contains ERA5 SLP for one time step\n",
    "DetectNodes \\\n",
    "--in_data \"/badc/ecmwf-era5/data/oper/an_sfc/1996/11/18/ecmwf-era5_oper_an_sfc_199611180000.msl.nc\" \\\n",
    "--out nodes.txt \\\n",
    "--searchbymin \"msl\" \\\n",
    "--latname \"latitude\" --lonname \"longitude\" \n",
    "# The output will summarize command arguments, and give you information about the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d4382b-7ec6-48b1-af0e-394db1a455f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize nodes.txt output file\n",
    "head nodes.txt\n",
    "# For each time step, list of candidate nodes \n",
    "# For each candidate node, contains lon. index, lat. index, lon. value and lat. value\n",
    "# Will contain more columns if more info is requested through the `outputcmd` argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056b1a95-7718-4164-94d4-2ddf76b1d2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean \n",
    "rm nodes.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a2889a-86ed-4161-91f9-c495286e2e9c",
   "metadata": {},
   "source": [
    "### `DetectNodes` over several files\n",
    "#### Several file of the same variable at different times\n",
    "If you want to search through several files at once, you need to create a text file listing the file paths, and then provide it to `--in_data_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08084a57-2837-4635-8187-a48c892e4e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /badc/ecmwf-era5/data/oper/an_sfc/1996/11/18/*msl* > flist.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133f0977-ac0a-4cc3-9420-04496dade2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder to store nodes in\n",
    "if ! [ -e nodes ]\n",
    "then\n",
    "    mkdir nodes\n",
    "else \n",
    "    echo \"nodes folder already exist, watch out for potential collisions.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6da75e2-c10e-4d97-8ab5-6c5d395a6aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DetectNodes \\\n",
    "--in_data_list flist.txt \\\n",
    "--out nodes/ \\\n",
    "--searchbymin \"msl\" \\\n",
    "--latname \"latitude\" --lonname \"longitude\" \n",
    "rm log* # Comment this if you need the log files for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb653d2-4755-46ed-81c2-fda2b191ab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f77163-9eeb-44d2-85a1-5b25f863bba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each file in nodes contains the list of candidate nodes for one input file\n",
    "head nodes/000000.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7276fa7-ece2-4b75-adde-20d658f9a14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean\n",
    "rm -rf nodes flist.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ac6851-b67e-4cfa-beca-b727d5ec4c8e",
   "metadata": {},
   "source": [
    "#### Several files of different variables at the same time\n",
    "The input filelist must contain all files path separated by a `;`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257fd67a-9cb5-4839-bd7e-3801265b238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we take msl, 10u and 10v files for a signle time step\n",
    "msl_file=\"/badc/ecmwf-era5/data/oper/an_sfc/1996/11/18/ecmwf-era5_oper_an_sfc_199611180000.msl.nc\"\n",
    "u10_file=\"/badc/ecmwf-era5/data/oper/an_sfc/1996/11/18/ecmwf-era5_oper_an_sfc_199611180000.10u.nc\"\n",
    "v10_file=\"/badc/ecmwf-era5/data/oper/an_sfc/1996/11/18/ecmwf-era5_oper_an_sfc_199611180000.10v.nc\"\n",
    "echo ${msl_file}\\;${u10_file}\\;${v10_file} > flist.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a0b9fa-1d37-4ac9-99bc-0a2d89a157c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note there is now a new lines \"outputcmd\" which specifies which information to add to output\n",
    "DetectNodes \\\n",
    "--in_data_list flist.txt \\\n",
    "--out nodes.txt \\\n",
    "--searchbymin \"msl\" \\\n",
    "--outputcmd \"msl,min,0;_VECMAG(u10,v10),max,2\" \\\n",
    "--mergedist \"6.0\" \\\n",
    "--latname \"latitude\" --lonname \"longitude\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f71ec0-5cec-4b87-a274-54162a5eeaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nodes file now contains two more coluns, with the SLP minimum and the 10m wind maximum\n",
    "head nodes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09f8db4-1cba-4452-9884-d05e56be03aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean\n",
    "rm nodes.txt flist.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2845fc75-9f95-4cc9-8e6e-f2e039b7fd46",
   "metadata": {},
   "source": [
    "#### Several files of different variables over several times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46af5cc-93a4-4dae-8da1-429362a24518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder to store nodes in\n",
    "if ! [ -e nodes ]; then mkdir nodes; \n",
    "else echo \"nodes folder already exist, watch out for potential collisions.\"; \n",
    "fi\n",
    "# Create folder to store logs in\n",
    "if ! [ -e logs ]; then mkdir logs; \n",
    "else echo \"logs folder already exist, watch out for potential collisions.\";\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdaddd0-33d2-4d2c-b254-d8100bd7e19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over time (in that case hours in a day)\n",
    "for h in 00 01 02 03 04\n",
    "do \n",
    "    echo $h\n",
    "    # Define the files for the different variables\n",
    "    msl_file=\"/badc/ecmwf-era5/data/oper/an_sfc/1996/11/18/ecmwf-era5_oper_an_sfc_19961118${h}00.msl.nc\"\n",
    "    u10_file=\"/badc/ecmwf-era5/data/oper/an_sfc/1996/11/18/ecmwf-era5_oper_an_sfc_19961118${h}00.10u.nc\"\n",
    "    v10_file=\"/badc/ecmwf-era5/data/oper/an_sfc/1996/11/18/ecmwf-era5_oper_an_sfc_19961118${h}00.10v.nc\"\n",
    "    # Concatenate them into flist.txt\n",
    "    echo ${msl_file}\\;${u10_file}\\;${v10_file} > flist.txt\n",
    "    \n",
    "    # Run DetectNodes for this time step\n",
    "    DetectNodes \\\n",
    "        --in_data_list flist.txt \\\n",
    "        --out nodes/${h}.txt \\\n",
    "        --searchbymin \"msl\" \\\n",
    "        --outputcmd \"msl,min,0;_VECMAG(u10,v10),max,2\" \\\n",
    "        --mergedist \"6.0\" \\\n",
    "        --latname \"latitude\" --lonname \"longitude\" > logs/${h}.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce49d217-8817-4be9-b527-a0f2194dd2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1ff897-87e2-4c86-adef-2bf41cc9a22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise file\n",
    "head nodes/00.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dc0f06-d4cb-4865-9f44-511c6447ad43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean\n",
    "rm -rf logs flist.txt\n",
    "# Do no remove nodes : We will use them next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08ca2a2-b991-45fc-976d-eb4bfc2e0d14",
   "metadata": {},
   "source": [
    "### Minimal `StitchNodes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e863450-95a9-44ae-8ad1-b275af0107f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create file with list of node files you want to use\n",
    "ls nodes/*.txt > flist.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273d5cb7-1dc2-494d-a7e8-266880e907e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call minimal StitchNodes\n",
    "StitchNodes \\\n",
    "--in_list flist.txt \\\n",
    "--in_fmt \"lon,lat,slp,wind10\" \\\n",
    "--out \"tracks.csv\" \\\n",
    "--out_file_format \"csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673992dd-73c0-405a-b7ce-7a365c0cfad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the tracks file\n",
    "head tracks.csv\n",
    "# For each track it identified, a track_id was defined\n",
    "# the csv contains information about the position in space and time for each point."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
